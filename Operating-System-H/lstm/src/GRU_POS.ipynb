{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drdh/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Activation,Dense,Dropout,RepeatVector,SpatialDropout1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedata=open(os.path.join(\"../data\",\"treebank_sents.txt\"),\"w\")\n",
    "ffdata=open(os.path.join(\"../data\",\"treebank_poss.txt\"),\"w\")\n",
    "\n",
    "sents=nltk.corpus.treebank.tagged_sents()\n",
    "for sent in sents:\n",
    "    words,poss=[],[]\n",
    "    for word,pos in sent:\n",
    "        if pos ==\"-NONE-\":\n",
    "            continue\n",
    "        words.append(word)\n",
    "        poss.append(pos)\n",
    "    fedata.write(\"{:s}\\n\".format(\" \".join(words)))\n",
    "    ffdata.write(\"{:s}\\n\".format(\" \".join(poss)))\n",
    "fedata.close()\n",
    "ffdata.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10947 249 3914\n",
      "45 249 3914\n"
     ]
    }
   ],
   "source": [
    "def parse_sentences(filename):\n",
    "    word_freqs=collections.Counter()\n",
    "    num_recs,maxlen=0,0\n",
    "    fin=open(filename,\"r\")\n",
    "    for line in fin:\n",
    "        words=line.strip().lower().split()\n",
    "        for word in words:\n",
    "            word_freqs[word]+=1\n",
    "        if(len(words)>maxlen):\n",
    "            maxlen=len(words)\n",
    "        num_recs+=1\n",
    "    fin.close()\n",
    "    return word_freqs,maxlen,num_recs\n",
    "\n",
    "s_wordfreqs,s_maxlen,s_numrecs=parse_sentences(os.path.join(\"../data\",\"treebank_sents.txt\"))\n",
    "t_wordfreqs,t_maxlen,t_numrecs=parse_sentences(os.path.join(\"../data\",\"treebank_poss.txt\"))\n",
    "print(len(s_wordfreqs),s_maxlen,s_numrecs)\n",
    "print(len(t_wordfreqs),t_maxlen,t_numrecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQLEN=250\n",
    "S_MAX_FEATURES=5000\n",
    "T_MAX_FEATURES=45\n",
    "\n",
    "s_vocabsize=min(len(s_wordfreqs),S_MAX_FEATURES)+2\n",
    "s_word2index={x[0]:i+2 for i,x in enumerate(s_wordfreqs.most_common(S_MAX_FEATURES))}\n",
    "s_word2index[\"PAD\"]=0\n",
    "s_word2index[\"UNK\"]=1\n",
    "s_index2word={v:k for k,v in s_word2index.items()}\n",
    "\n",
    "t_vocabsize=len(t_wordfreqs)+1\n",
    "t_word2index={x[0]:i for i,x in enumerate(t_wordfreqs.most_common(T_MAX_FEATURES))}\n",
    "\n",
    "t_word2index[\"PAD\"]=0\n",
    "t_index2word={v:k for k,v in t_word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tensor(filename,numrecs,word2index,maxlen,make_categorical=False,num_classes=0):\n",
    "    data=np.empty((numrecs,),dtype=list)\n",
    "    fin=open(filename,\"r\")\n",
    "    i=0\n",
    "    for line in fin:\n",
    "        wids=[]\n",
    "        for word in line.strip().lower().split():\n",
    "            if word in word2index:\n",
    "                wids.append(word2index[word])\n",
    "            else:\n",
    "                wids.append(word2index[\"UNK\"])\n",
    "        if make_categorical:\n",
    "            data[i]=np_utils.to_categorical(wids,num_classes=num_classes)\n",
    "        else:\n",
    "            data[i]=wids\n",
    "        i+=1\n",
    "    fin.close()\n",
    "    pdata=sequence.pad_sequences(data,maxlen=maxlen)\n",
    "    return pdata\n",
    "\n",
    "X=build_tensor(os.path.join(\"../data\",\"treebank_sents.txt\"),s_numrecs,s_word2index,MAX_SEQLEN)\n",
    "Y=build_tensor(os.path.join(\"../data\",\"treebank_poss.txt\"),t_numrecs,t_word2index,MAX_SEQLEN,True,t_vocabsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE=128\n",
    "HIDDEN_SIZE=64\n",
    "BATCH_SIZE=32\n",
    "NUM_EPOCHS=1\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(s_vocabsize,EMBED_SIZE,input_length=MAX_SEQLEN))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(GRU(HIDDEN_SIZE,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(RepeatVector(MAX_SEQLEN))\n",
    "model.add(GRU(HIDDEN_SIZE,return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(t_vocabsize)))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model,to_file=\"GRU_POS.png\",show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3131 samples, validate on 783 samples\n",
      "Epoch 1/1\n",
      "3131/3131 [==============================] - 43s 14ms/step - loss: 0.3016 - acc: 0.7295 - val_loss: 0.2929 - val_acc: 0.9157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40fdcfba90>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,Ytrain,batch_size=BATCH_SIZE,epochs=NUM_EPOCHS,validation_data=[Xtest,Ytest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 2s 3ms/step\n",
      "0.2928801686294843 0.9157496759261208\n"
     ]
    }
   ],
   "source": [
    "score,acc=model.evaluate(Xtest,Ytest,batch_size=BATCH_SIZE)\n",
    "print(score,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3131 samples, validate on 783 samples\n",
      "Epoch 1/1\n",
      "3131/3131 [==============================] - 52s 17ms/step - loss: 0.2893 - acc: 0.7489 - val_loss: 0.2782 - val_acc: 0.8367\n",
      "783/783 [==============================] - 3s 4ms/step\n",
      "0.27818018513925535 0.8367100931979992\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(s_vocabsize,EMBED_SIZE,input_length=MAX_SEQLEN))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Bidirectional(GRU(HIDDEN_SIZE,dropout=0.2,recurrent_dropout=0.2)))\n",
    "model.add(RepeatVector(MAX_SEQLEN))\n",
    "model.add(Bidirectional(GRU(HIDDEN_SIZE,return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(t_vocabsize)))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "plot_model(model,to_file=\"Bidirectional_POS.png\",show_shapes=True)\n",
    "\n",
    "model.fit(Xtrain,Ytrain,batch_size=BATCH_SIZE,epochs=NUM_EPOCHS,validation_data=[Xtest,Ytest])\n",
    "\n",
    "score,acc=model.evaluate(Xtest,Ytest,batch_size=BATCH_SIZE)\n",
    "print(score,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3131 samples, validate on 783 samples\n",
      "Epoch 1/1\n",
      "3131/3131 [==============================] - 47s 15ms/step - loss: 0.3011 - acc: 0.8290 - val_loss: 0.2939 - val_acc: 0.9079\n",
      "783/783 [==============================] - 2s 3ms/step\n",
      "0.2939024456463859 0.9078876208680495\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(s_vocabsize,EMBED_SIZE,input_length=MAX_SEQLEN))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(HIDDEN_SIZE,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(RepeatVector(MAX_SEQLEN))\n",
    "model.add(LSTM(HIDDEN_SIZE,return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(t_vocabsize)))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "plot_model(model,to_file=\"LSTM_POS.png\",show_shapes=True)\n",
    "\n",
    "model.fit(Xtrain,Ytrain,batch_size=BATCH_SIZE,epochs=NUM_EPOCHS,validation_data=[Xtest,Ytest])\n",
    "\n",
    "score,acc=model.evaluate(Xtest,Ytest,batch_size=BATCH_SIZE)\n",
    "print(score,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
